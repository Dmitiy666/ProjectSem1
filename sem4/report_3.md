# Отчет 3. Исследование метода Q-learning в среде Frozen Lake 

## 1. Сравнение c изменением параметра альфы

Для алгоритма `V learning` на поле (4х4) при `gamma=0.9` сходимость (mean reward > 0.85) достигается в среднем за 53 итерации (от 30 до 85). 
Графики зависимости reward от количества итераций приведены ниже. 

<img src="image/V.PNG"/>

Для алгоритма `Q learning` на поле (4х4) при `gamma=0.9` сходимость (mean reward > 0.85) достигается в среднем за 53 итерации (от 16 до 56). 
Графики зависимости reward от количества итераций приведены ниже. 

<img src="image/Q.PNG"/>

**Вывод:** Алгоритм обучения ценности состояний более эффективен чем обучение ценности действий. Это связано с тем, что ... 
